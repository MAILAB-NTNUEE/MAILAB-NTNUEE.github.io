---
title: "Publications"
layout: single
permalink: /publications/
classes:
  - wide
header:
  overlay_image: /assets/images/publications-header.jpg
  overlay_filter: 0.5
  caption: "Photo credit: [**Unsplash**](https://unsplash.com)"
---

<div class="feature-section">
  <div class="feature-container">
    <p style="text-align: center; max-width: 800px; margin: 0 auto 3rem;">
      Our lab members publish in top-tier conferences and journals in computer vision, machine learning, and multimedia analysis.
    </p>
    
    <div style="margin-bottom: 2rem;">
      <h3>Filter by Year:</h3>
      <div style="text-align: center; margin-bottom: 1rem;">
        <a href="#2025" class="hero-button">2025</a>
        <a href="#2024" class="hero-button">2024</a>
        <a href="#2023" class="hero-button">2023</a>
        <a href="#2022" class="hero-button">2022</a>
        <a href="#2021" class="hero-button">2021</a>
      </div>
    </div>

    <h2 id="2025" style="border-bottom: 2px solid #56C596; padding-bottom: 0.5rem;">2025</h2>
    
    <div class="publication-list">
      <div class="publication-item">
        <h3 class="pub-title">Transformer-based Neural Architecture for Multimodal Image Segmentation</h3>
        <p class="pub-authors">Lee, J., Chen, T., Wang, H., & Zhang, Y.</p>
        <p class="pub-journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025</p>
        <p>This paper presents a novel transformer-based architecture for multimodal image segmentation that effectively fuses information from multiple sensors. Our approach achieves state-of-the-art performance on benchmark datasets while being computationally efficient.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
          <a href="#" target="_blank"><i class="fas fa-code"></i> Code</a>
        </div>
      </div>
      
      <div class="publication-item">
        <h3 class="pub-title">Self-Supervised Learning for Medical Image Analysis with Limited Annotations</h3>
        <p class="pub-authors">Wang, H., Zhang, Y., Lee, J., & Chen, T.</p>
        <p class="pub-journal">Medical Image Analysis, 2025</p>
        <p>We propose a self-supervised learning framework specifically designed for medical imaging applications where annotated data is scarce. Our method leverages anatomical priors to guide the learning process, resulting in more accurate segmentation and classification models.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
        </div>
      </div>
    </div>
    
    <h2 id="2024" style="border-bottom: 2px solid #56C596; padding-bottom: 0.5rem; margin-top: 3rem;">2024</h2>
    
    <div class="publication-list">
      <div class="publication-item">
        <h3 class="pub-title">Efficient Neural Networks for Real-time Video Understanding</h3>
        <p class="pub-authors">Chen, T., Lee, J., Wang, H., & Zhang, Y.</p>
        <p class="pub-journal">International Conference on Machine Learning (ICML), 2024</p>
        <p>This work introduces a family of efficient neural networks designed for real-time video understanding tasks. Our architectures achieve competitive performance while requiring significantly less computational resources, making them suitable for deployment on edge devices.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
          <a href="#" target="_blank"><i class="fas fa-code"></i> Code</a>
        </div>
      </div>
      
      <div class="publication-item">
        <h3 class="pub-title">Vision-Language Models for Automated Medical Report Generation</h3>
        <p class="pub-authors">Zhang, Y., Wang, H., Chen, T., & Lee, J.</p>
        <p class="pub-journal">IEEE Transactions on Medical Imaging, 2024</p>
        <p>We present an end-to-end vision-language model that can automatically generate accurate and detailed medical reports from radiological images. Our model incorporates domain knowledge and can explain its reasoning, improving trust and adoption in clinical settings.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
        </div>
      </div>
    </div>
    
    <h2 id="2023" style="border-bottom: 2px solid #56C596; padding-bottom: 0.5rem; margin-top: 3rem;">2023</h2>
    
    <div class="publication-list">
      <div class="publication-item">
        <h3 class="pub-title">Contrastive Learning for Unsupervised Video Representation</h3>
        <p class="pub-authors">Chen, T., Zhang, Y., Wang, H., & Lee, J.</p>
        <p class="pub-journal">International Conference on Computer Vision (ICCV), 2023</p>
        <p>This work explores contrastive learning approaches for learning robust video representations without human supervision. By leveraging temporal consistency and multi-view information, our method achieves competitive performance on downstream tasks with minimal labeled data.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
          <a href="#" target="_blank"><i class="fas fa-code"></i> Code</a>
        </div>
      </div>
      
      <div class="publication-item">
        <h3 class="pub-title">Generative Adversarial Networks for Data Augmentation in Medical Imaging</h3>
        <p class="pub-authors">Wang, H., Chen, T., Lee, J., & Zhang, Y.</p>
        <p class="pub-journal">Neural Information Processing Systems (NeurIPS), 2023</p>
        <p>We develop a novel GAN architecture specifically designed for generating realistic medical images that can be used for data augmentation. Our approach addresses the challenge of limited training data in medical image analysis by generating diverse, anatomically correct samples.</p>
        <div class="pub-links">
          <a href="#" target="_blank"><i class="fas fa-external-link-alt"></i> DOI</a>
          <a href="#" target="_blank"><i class="far fa-file-pdf"></i> PDF</a>
          <a href="#" target="_blank"><i class="fas fa-code"></i> Code</a>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="feature-section grid-pattern">
  <div class="feature-container">
    <div class="section-heading">
      <h2>Publication Statistics</h2>
    </div>
    
    <div style="display: flex; flex-wrap: wrap; justify-content: space-around; text-align: center; margin: 2rem 0;">
      <div style="flex: 1; min-width: 200px; margin: 1rem;">
        <h3 style="color: #1E5F74; font-size: 3rem; margin: 0;">24+</h3>
        <p>Journal Articles</p>
      </div>
      <div style="flex: 1; min-width: 200px; margin: 1rem;">
        <h3 style="color: #1E5F74; font-size: 3rem; margin: 0;">45+</h3>
        <p>Conference Papers</p>
      </div>
      <div style="flex: 1; min-width: 200px; margin: 1rem;">
        <h3 style="color: #1E5F74; font-size: 3rem; margin: 0;">12+</h3>
        <p>Patents</p>
      </div>
      <div style="flex: 1; min-width: 200px; margin: 1rem;">
        <h3 style="color: #1E5F74; font-size: 3rem; margin: 0;">1500+</h3>
        <p>Citations</p>
      </div>
    </div>
  </div>
</div>